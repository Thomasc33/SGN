{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import pickle\n",
    "from model import SGN\n",
    "from data import NTUDataLoaders, AverageMeter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import h5py\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "with open('data/ntu120/X_full.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "# Remove actions above 120\n",
    "to_rem = []\n",
    "for file in X.keys():\n",
    "    if int(str(file).split('A')[1][:3]) > 60:\n",
    "        to_rem.append(file)\n",
    "for file in to_rem:\n",
    "    del X[file]\n",
    "\n",
    "def reshape_skeleton(skeleton):\n",
    "    \"\"\"\n",
    "    Reshape the skeleton data from shape [300, 150] to [20, 75].\n",
    "    \"\"\"\n",
    "    skeleton = skeleton[:20, :75]\n",
    "    return skeleton\n",
    "\n",
    "def predict_sgn(model, skeleton):\n",
    "    skeleton = torch.tensor(skeleton).cuda()\n",
    "    model.cuda()\n",
    "    out = model.eval_single(skeleton)\n",
    "    out = out.view((-1, skeleton.size(0)//skeleton.size(0), out.size(1)))\n",
    "    out = out.mean(1)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    out = np.argmax(out, axis=1)\n",
    "    return out\n",
    "\n",
    "\n",
    "args = SimpleNamespace(batch_size=batch_size, train=0)\n",
    "\n",
    "sgn_ar = SGN(60, None, 20, args, 0).cuda()\n",
    "sgn_priv = SGN(40, None, 20, args, 0).cuda()\n",
    "sgn_ar.load_state_dict(torch.load('pretrained/action_60_sgnpt.pt')['state_dict'], strict=False)\n",
    "sgn_priv.load_state_dict(torch.load('pretrained/privacy_60_sgnpt.pt')['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "feature_names = [\"frame_{}_joint_{}_coord_{}\".format(frame, joint, coord)\n",
    "                   for frame in range(20) for joint in range(25) for coord in ['x', 'y', 'z']]\n",
    "\n",
    "# Initialize LIME explainer\n",
    "ar_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array([reshape_skeleton(v).flatten() for v in X.values()]),  # Flattened training data\n",
    "    feature_names=feature_names,\n",
    "    mode='classification',\n",
    "    class_names=['Action_{}'.format(i) for i in range(60)],  # Replace with actual class names if available\n",
    "    training_labels=np.array([int(k[19:22]) - 1 for k in X.keys()]),  # Assuming action label is embedded in file name\n",
    ")\n",
    "\n",
    "ri_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array([reshape_skeleton(v).flatten() for v in X.values()]),  # Flattened training data\n",
    "    feature_names=feature_names,\n",
    "    mode='classification',\n",
    "    class_names=['Action_{}'.format(i) for i in range(40)],  # Replace with actual class names if available\n",
    "    training_labels=np.array([int(k[9:12]) - 1 for k in X.keys()]),  # Assuming action label is embedded in file name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "instance_limiter = 1\n",
    "\n",
    "# Sample a subset of instances for testing\n",
    "sampled_instances = random.sample(list(X.keys()), instance_limiter)\n",
    "\n",
    "# Storage for joint-wise importance scores\n",
    "joint_importances_ar = {joint: [] for joint in range(25)}  # For Action Recognition\n",
    "joint_importances_ri = {joint: [] for joint in range(25)}  # For Re-identification\n",
    "\n",
    "# Prediction functions for both models\n",
    "def predict_fn_ar(input_skeleton):\n",
    "    input_skeleton = input_skeleton.reshape(-1, 20, 75)\n",
    "    input_tensor = torch.tensor(input_skeleton, dtype=torch.float32).cuda()\n",
    "    with torch.no_grad():\n",
    "        output = sgn_ar.eval_single(input_tensor)\n",
    "        output = torch.softmax(output, 1).cpu().numpy()\n",
    "    return output\n",
    "\n",
    "def predict_fn_ri(input_skeleton):\n",
    "    input_skeleton = input_skeleton.reshape(-1, 20, 75)\n",
    "    input_tensor = torch.tensor(input_skeleton, dtype=torch.float32).cuda()\n",
    "    with torch.no_grad():\n",
    "        output = sgn_priv.eval_single(input_tensor)\n",
    "        output = torch.softmax(output, 1).cpu().numpy()\n",
    "    return output\n",
    "\n",
    "# Iterate through the data and collect explanations\n",
    "for file_name in sampled_instances:\n",
    "    print('Gathering explanation for: ', file_name)\n",
    "    A = int(file_name[19:22]) - 1\n",
    "    P = int(file_name[9:12]) - 1\n",
    "    skeleton = X[file_name]\n",
    "\n",
    "    reshaped_skeleton = reshape_skeleton(skeleton)\n",
    "    flattened_skeleton = reshaped_skeleton.flatten()\n",
    "\n",
    "    # Get LIME explanation for Action Recognition\n",
    "    explanation_ar = ar_explainer.explain_instance(flattened_skeleton, predict_fn_ar, num_features=20*25*3, labels=[A])\n",
    "\n",
    "    # Get LIME explanation for Re-identification\n",
    "    explanation_ri = ri_explainer.explain_instance(flattened_skeleton, predict_fn_ri, num_features=20*25*3, labels=[P])\n",
    "\n",
    "    # Collect importance for each joint from both models\n",
    "    for feature_index, importance_value in explanation_ar.local_exp[A]:  # Assuming class 0\n",
    "        feature_name = ar_explainer.feature_names[feature_index]\n",
    "        # Extract joint number from feature name (e.g., \"frame_0_joint_7_coord_y\")\n",
    "        joint_num = int(feature_name.split('_')[3])\n",
    "        joint_importances_ar[joint_num].append(importance_value)\n",
    "\n",
    "    for feature_index, importance_value in explanation_ri.local_exp[P]:  # Assuming class 0\n",
    "        feature_name = ri_explainer.feature_names[feature_index]\n",
    "        joint_num = int(feature_name.split('_')[3])\n",
    "        joint_importances_ri[joint_num].append(importance_value)\n",
    "\n",
    "# Calculate absolute values of average importances\n",
    "average_importances_ar = {joint: np.abs(importance) for joint, importance in joint_importances_ar.items()}\n",
    "average_importances_ri = {joint: np.abs(importance) for joint, importance in joint_importances_ri.items()}\n",
    "\n",
    "# Average the importance scores across sequences for each joint\n",
    "average_importances_ar = {joint: np.mean(importance) for joint, importance in average_importances_ar.items()}\n",
    "average_importances_ri = {joint: np.mean(importance) for joint, importance in average_importances_ri.items()}\n",
    "\n",
    "# Display the average importances\n",
    "print('Average importances for Action Recognition:')\n",
    "for joint, importance in average_importances_ar.items():\n",
    "    print('Joint {}: {}'.format(joint, importance))\n",
    "\n",
    "print('Average importances for Re-identification:')\n",
    "for joint, importance in average_importances_ri.items():\n",
    "    print('Joint {}: {}'.format(joint, importance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
