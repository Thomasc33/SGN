{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import pickle\n",
    "from model import SGN\n",
    "from data import NTUDataLoaders, AverageMeter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import h5py\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carrt\\AppData\\Local\\Temp\\ipykernel_29700\\316607567.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sgn_ar.load_state_dict(torch.load('pretrained/action_60_sgnpt.pt')['state_dict'], strict=False)\n",
      "C:\\Users\\Carrt\\AppData\\Local\\Temp\\ipykernel_29700\\316607567.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sgn_priv.load_state_dict(torch.load('pretrained/privacy_60_sgnpt.pt')['state_dict'], strict=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['tem_embed.cnn.0.cnn.bias', 'tem_embed.cnn.2.cnn.bias', 'spa_embed.cnn.0.cnn.bias', 'spa_embed.cnn.2.cnn.bias', 'joint_embed.cnn.1.cnn.bias', 'joint_embed.cnn.3.cnn.bias', 'dif_embed.cnn.1.cnn.bias', 'dif_embed.cnn.3.cnn.bias', 'cnn.cnn1.bias', 'cnn.cnn2.bias', 'compute_g1.g1.cnn.bias', 'compute_g1.g2.cnn.bias', 'gcn1.w1.cnn.bias', 'gcn2.w1.cnn.bias', 'gcn3.w1.cnn.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "with open('ntu/SGN/X_full.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "def reshape_skeleton(skeleton):\n",
    "    \"\"\"\n",
    "    Reshape the skeleton data from shape [300, 150] to [20, 75].\n",
    "    \"\"\"\n",
    "    skeleton = skeleton[:20, :75]\n",
    "    return skeleton\n",
    "\n",
    "def predict_sgn(model, skeleton):\n",
    "    skeleton = torch.tensor(skeleton).cuda()\n",
    "    model.cuda()\n",
    "    out = model.eval_single(skeleton)\n",
    "    out = out.view((-1, skeleton.size(0)//skeleton.size(0), out.size(1)))\n",
    "    out = out.mean(1)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    out = np.argmax(out, axis=1)\n",
    "    return out\n",
    "\n",
    "\n",
    "args = SimpleNamespace(batch_size=batch_size, train=0)\n",
    "\n",
    "sgn_ar = SGN(60, None, 20, args, 0).cuda()\n",
    "sgn_priv = SGN(40, None, 20, args, 0).cuda()\n",
    "sgn_ar.load_state_dict(torch.load('pretrained/action_60_sgnpt.pt')['state_dict'], strict=False)\n",
    "sgn_priv.load_state_dict(torch.load('pretrained/privacy_60_sgnpt.pt')['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_joint_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_coord_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(frame, joint, coord)\n\u001b[0;32m      6\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m joint \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize LIME explainer\u001b[39;00m\n\u001b[0;32m      9\u001b[0m ar_explainer \u001b[38;5;241m=\u001b[39m lime\u001b[38;5;241m.\u001b[39mlime_tabular\u001b[38;5;241m.\u001b[39mLimeTabularExplainer(\n\u001b[1;32m---> 10\u001b[0m     training_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([reshape_skeleton(v)\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m()]),  \u001b[38;5;66;03m# Flattened training data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m     12\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     class_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAction_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m)],  \u001b[38;5;66;03m# Replace with actual class names if available\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     training_labels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mint\u001b[39m(k[\u001b[38;5;241m19\u001b[39m:\u001b[38;5;241m22\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mkeys()]),  \u001b[38;5;66;03m# Assuming action label is embedded in file name\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m ri_explainer \u001b[38;5;241m=\u001b[39m lime\u001b[38;5;241m.\u001b[39mlime_tabular\u001b[38;5;241m.\u001b[39mLimeTabularExplainer(\n\u001b[0;32m     18\u001b[0m     training_data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([reshape_skeleton(v)\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mvalues()]),  \u001b[38;5;66;03m# Flattened training data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     training_labels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mint\u001b[39m(k[\u001b[38;5;241m9\u001b[39m:\u001b[38;5;241m12\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mkeys()]),  \u001b[38;5;66;03m# Assuming action label is embedded in file name\u001b[39;00m\n\u001b[0;32m     23\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "feature_names = [\"frame_{}_joint_{}_coord_{}\".format(frame, joint, coord)\n",
    "                   for frame in range(20) for joint in range(25) for coord in ['x', 'y', 'z']]\n",
    "\n",
    "# Initialize LIME explainer\n",
    "ar_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array([reshape_skeleton(v).flatten() for v in X.values()]),  # Flattened training data\n",
    "    feature_names=feature_names,\n",
    "    mode='classification',\n",
    "    class_names=['Action_{}'.format(i) for i in range(60)],  # Replace with actual class names if available\n",
    "    training_labels=np.array([int(k[19:22]) - 1 for k in X.keys()]),  # Assuming action label is embedded in file name\n",
    ")\n",
    "\n",
    "ri_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array([reshape_skeleton(v).flatten() for v in X.values()]),  # Flattened training data\n",
    "    feature_names=feature_names,\n",
    "    mode='classification',\n",
    "    class_names=['Action_{}'.format(i) for i in range(40)],  # Replace with actual class names if available\n",
    "    training_labels=np.array([int(k[9:12]) - 1 for k in X.keys()]),  # Assuming action label is embedded in file name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "instance_limiter = 1\n",
    "\n",
    "# Sample a subset of instances for testing\n",
    "sampled_instances = random.sample(list(X.keys()), instance_limiter)\n",
    "\n",
    "# Storage for joint-wise importance scores\n",
    "joint_importances_ar = {joint: [] for joint in range(25)}  # For Action Recognition\n",
    "joint_importances_ri = {joint: [] for joint in range(25)}  # For Re-identification\n",
    "\n",
    "# Prediction functions for both models\n",
    "def predict_fn_ar(input_skeleton):\n",
    "    input_skeleton = input_skeleton.reshape(-1, 20, 75)\n",
    "    input_tensor = torch.tensor(input_skeleton, dtype=torch.float32).cuda()\n",
    "    with torch.no_grad():\n",
    "        output = sgn_ar.eval_single(input_tensor)\n",
    "        output = torch.softmax(output, 1).cpu().numpy()\n",
    "    return output\n",
    "\n",
    "def predict_fn_ri(input_skeleton):\n",
    "    input_skeleton = input_skeleton.reshape(-1, 20, 75)\n",
    "    input_tensor = torch.tensor(input_skeleton, dtype=torch.float32).cuda()\n",
    "    with torch.no_grad():\n",
    "        output = sgn_priv.eval_single(input_tensor)\n",
    "        output = torch.softmax(output, 1).cpu().numpy()\n",
    "    return output\n",
    "\n",
    "# Iterate through the data and collect explanations\n",
    "for file_name in sampled_instances:\n",
    "    print('Gathering explanation for: ', file_name)\n",
    "    A = int(file_name[19:22]) - 1\n",
    "    P = int(file_name[9:12]) - 1\n",
    "    skeleton = X[file_name]\n",
    "\n",
    "    reshaped_skeleton = reshape_skeleton(skeleton)\n",
    "    flattened_skeleton = reshaped_skeleton.flatten()\n",
    "\n",
    "    # Get LIME explanation for Action Recognition\n",
    "    explanation_ar = ar_explainer.explain_instance(flattened_skeleton, predict_fn_ar, num_features=20*25*3, labels=[A])\n",
    "\n",
    "    # Get LIME explanation for Re-identification\n",
    "    explanation_ri = ri_explainer.explain_instance(flattened_skeleton, predict_fn_ri, num_features=20*25*3, labels=[P])\n",
    "\n",
    "    # Collect importance for each joint from both models\n",
    "    for feature_index, importance_value in explanation_ar.local_exp[A]:  # Assuming class 0\n",
    "        feature_name = ar_explainer.feature_names[feature_index]\n",
    "        # Extract joint number from feature name (e.g., \"frame_0_joint_7_coord_y\")\n",
    "        joint_num = int(feature_name.split('_')[3])\n",
    "        joint_importances_ar[joint_num].append(importance_value)\n",
    "\n",
    "    for feature_index, importance_value in explanation_ri.local_exp[P]:  # Assuming class 0\n",
    "        feature_name = ri_explainer.feature_names[feature_index]\n",
    "        joint_num = int(feature_name.split('_')[3])\n",
    "        joint_importances_ri[joint_num].append(importance_value)\n",
    "\n",
    "# Average the importance scores across sequences for each joint\n",
    "average_importances_ar = {joint: np.mean(importance) for joint, importance in joint_importances_ar.items()}\n",
    "average_importances_ri = {joint: np.mean(importance) for joint, importance in joint_importances_ri.items()}\n",
    "\n",
    "# Compare AR vs. RI to find joints with the specific patterns\n",
    "positive_ar_negative_ri = []\n",
    "negative_ar_positive_ri = []\n",
    "\n",
    "for joint in range(25):\n",
    "    if average_importances_ar[joint] > 0 and average_importances_ri[joint] < 0:\n",
    "        positive_ar_negative_ri.append(joint)\n",
    "    if average_importances_ar[joint] < 0 and average_importances_ri[joint] > 0:\n",
    "        negative_ar_positive_ri.append(joint)\n",
    "\n",
    "# Output the results\n",
    "print('Below are zero indexed (so add 1 when looking at the joint number):')\n",
    "print(\"Joints with positive importance for AR but negative for RI:\", positive_ar_negative_ri)\n",
    "print(\"Joints with negative importance for AR but positive for RI:\", negative_ar_positive_ri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
